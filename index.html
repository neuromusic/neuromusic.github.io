---
layout: default
title: Justin Kiggins
---
<div class="home" id="home">
  <p class="intro">Ph.D. Candidate in Neurosciences, UC San Diego</p>
  <p>My research explores the way that vocal communication signals are perceived and represented. More specifically, I'm interested in how neural systems represent and learn sequences like those found in speech and music. The integration time of these signals (hundreds to thousands of milliseconds) pose particular challenges to spectrotemporal receptive field models, which typically only integrate over tens of milliseconds. I employ automated behavioral training, extracellular electrophysiology, and computational analyses to answer these questions.</p>

  <h2>Code</h2>
  <ul>
    <li><a href="https://github.com/gentnerlab/pyoperant">PyOperant</a>: hardware abstraction and shareable protocols for operant conditioning</li>
    <li><a href="https://github.com/gentnerlab/django-broab">django-broab</a>: extendable Django models for electrophysiology data</li>
    <li><a href="https://github.com/gentnerlab/sturnus">sturnus</a>: Django site for storing behavior and neurophysiology data</li>
  </ul>
</div>